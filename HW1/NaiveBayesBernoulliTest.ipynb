{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Builds a Bernoulli naive Bayes classifier\n",
    "\"\"\"\n",
    "\n",
    "from math import log\n",
    "import glob\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def get_features(text):\n",
    "    \"\"\"Extracts features from text\n",
    "\n",
    "    Args:\n",
    "        text (str): A blob of unstructured text\n",
    "    \"\"\"\n",
    "    return set([w.lower() for w in text.split(\" \")])\n",
    "\n",
    "\n",
    "class BernoulliNBTextClassifier(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._log_priors = None\n",
    "        self._cond_probs = None\n",
    "        self.features = None\n",
    "\n",
    "    def train(self, documents, labels):\n",
    "        \"\"\"Train a Bernoulli naive Bayes classifier\n",
    "\n",
    "        Args:\n",
    "            documents (list): Each element in this list\n",
    "                is a blog of text\n",
    "            labels (list): The ground truth label for\n",
    "                each document\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"Compute log( P(Y) )\n",
    "        \"\"\"\n",
    "        label_counts = Counter(labels)\n",
    "        N = float(sum(label_counts.values()))\n",
    "        self._log_priors = {k: log(v/N) for k, v in label_counts.iteritems()}\n",
    "\n",
    "        \"\"\"Feature extraction\n",
    "        \"\"\"\n",
    "        # Extract features from each document\n",
    "        X = [set(get_features(d)) for d in documents]\n",
    "\n",
    "        # Get all features\n",
    "        self.features = set([f for features in X for f in features])\n",
    "\n",
    "        \"\"\"Compute log( P(X|Y) )\n",
    "\n",
    "           Use Laplace smoothing\n",
    "           n1 + 1 / (n1 + n2 + 2)\n",
    "        \"\"\"\n",
    "        self._cond_probs = {l: {f: 0. for f in self.features} for l in self._log_priors}\n",
    "\n",
    "        # Step through each document\n",
    "        for x, l in zip(X, labels):\n",
    "            for f in x:\n",
    "                self._cond_probs[l][f] += 1.\n",
    "\n",
    "        # Now, compute log probs\n",
    "        for l in self._cond_probs:\n",
    "            N = label_counts[l]\n",
    "            self._cond_probs[l] = {f: (v + 1.) / (N + 2.) for f, v in self._cond_probs[l].iteritems()}\n",
    "\n",
    "    def predict(self, text):\n",
    "        \"\"\"Make a prediction from text\n",
    "        \"\"\"\n",
    "\n",
    "        # Extract features\n",
    "        x = get_features(text)\n",
    "\n",
    "        pred_class = None\n",
    "        max_ = float(\"-inf\")\n",
    "\n",
    "        # Perform MAP estimation\n",
    "        for l in self._log_priors:\n",
    "            log_sum = self._log_priors[l]\n",
    "            for f in self.features:\n",
    "                prob = self._cond_probs[l][f]\n",
    "                log_sum += log(prob if f in x else 1. - prob)\n",
    "            if log_sum > max_:\n",
    "                max_ = log_sum\n",
    "                pred_class = l\n",
    "\n",
    "        return pred_class\n",
    "\n",
    "\n",
    "def get_labeled_data(type_):\n",
    "    \"\"\"Get data from:\n",
    "    \n",
    "        http://openclassroom.stanford.edu/\n",
    "        MainFolder/courses/MachineLearning/\n",
    "        exercises/ex6materials/\n",
    "        ex6DataEmails.zip\n",
    "        \n",
    "        Create a folder named 'emails' with content from ex6DataEmails in\n",
    "        same directory as this script\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    labels = []\n",
    "\n",
    "    file_names = glob.glob('./emails/spam-{0}/*.txt'.format(type_))\n",
    "    for n in file_names:\n",
    "        f = open(n)\n",
    "        examples.append(f.read())\n",
    "        labels.append('spam')\n",
    "        f.close()\n",
    "\n",
    "    file_names = glob.glob('./emails/nonspam-{0}/*.txt'.format(type_))\n",
    "    for n in file_names:\n",
    "        f = open(n)\n",
    "        examples.append(f.read())\n",
    "        labels.append('nonspam')\n",
    "        f.close()\n",
    "\n",
    "    return examples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
