{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/\n",
    "#https://github.com/GPSingularity/Machine-Learning-in-Python/blob/master/nbsingularity.py\n",
    "\n",
    "\n",
    "#https://mattshomepage.com/articles/2016/Jun/07/bernoulli_nb/\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import random\n",
    "import math\n",
    "raw_data = pd.read_csv('/Users/psaxena21/Documents/Mine/AML/pima-indians-diabetes.csv', header=None)\n",
    "d = raw_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self, ignoreMissingVal):\n",
    "        self.ignoreMissingVal = ignoreMissingVal\n",
    "\n",
    "    def testTrainSplit(self, data, ratio):\n",
    "        localCopy = list(data)\n",
    "        testSize = int(len(data) * ratio)\n",
    "        testData = []\n",
    "        while len(testData) < testSize:\n",
    "            testData.append(localCopy.pop(random.randrange(len(localCopy))))\n",
    "        testNPArr  = np.array(testData)\n",
    "        trainNPArr = np.array(localCopy)\n",
    "        return trainNPArr[:, :8], trainNPArr[:, 8].astype(int), testNPArr[:, :8], testNPArr[:, 8].astype(int)\n",
    "            \n",
    "    def fit(self, X, Y):\n",
    "        self.normDF = {}\n",
    "        self.priors = {}\n",
    "        categories = set(Y)\n",
    "        if self.ignoreMissingVal:\n",
    "            X[X == 0] = np.nan\n",
    "        for c in categories:\n",
    "            XForC = X[Y == c]\n",
    "            self.normDF[c] = {\n",
    "                'mean' : np.nanmean(XForC, axis=0),\n",
    "                'var': np.nanvar(XForC, axis=0)\n",
    "            }\n",
    "            self.priors[c] = 1.0 * len(Y[Y == c])/ len(Y)\n",
    "            \n",
    "    def __calculateProbability(self, x, mean, stdev):\n",
    "        exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "        return (1.0 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    "    \n",
    "    def __calculateLogNormPdf(self, X, mean, stddev):\n",
    "        local_X = X[X != 0] if self.ignoreMissingVal else X\n",
    "        local_mean = mean[X != 0] if self.ignoreMissingVal else mean\n",
    "        local_stddev = stddev[X != 0] if self.ignoreMissingVal else stddev\n",
    "        return np.log(np.array([self.__calculateProbability(local_X[i], local_mean[i], local_stddev[i]) for i in range(len(local_X))]))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        P = {}\n",
    "        for c, g in self.normDF.items():\n",
    "            # print \"c:\", c\n",
    "            mean, var = g['mean'], g['var']\n",
    "            classConditionalProb = 0\n",
    "#             classConditionalProb = np.nansum(np.log(norm.pdf(X[X, mean, np.sqrt(var))))\n",
    "            classConditionalProb = np.sum(self.__calculateLogNormPdf(X, mean, np.sqrt(var)))\n",
    "            P[c] = classConditionalProb + np.log(self.priors[c])  \n",
    "\n",
    "            bestCategory, bestProb = None, float(\"-inf\")\n",
    "        for category, probability in P.items():\n",
    "            if bestCategory is None or probability > bestProb:\n",
    "                bestProb = probability\n",
    "                bestCategory = category\n",
    "        return bestCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy over 10 test-train splits and without ignoring missing values is 75.490196\n",
      "Average accuracy over 10 test-train splits and ignoring missing values is 74.313725\n"
     ]
    }
   ],
   "source": [
    "def runClassifier(data, ignoreMissingVal=False):\n",
    "    accuracy = 0\n",
    "    for i in range(10):\n",
    "        nb = NaiveBayes(ignoreMissingVal)\n",
    "        np.random.shuffle(data)\n",
    "        X_Train, Y_Train, X_Test, Y_Test = nb.testTrainSplit(data, 0.20)\n",
    "        nb.fit(X_Train, Y_Train)\n",
    "        correct = 0\n",
    "        for i in range(len(Y_Test)):\n",
    "            Y_Pred = nb.predict(X_Test[i])\n",
    "            if Y_Test[i] == Y_Pred:\n",
    "                correct += 1\n",
    "        accuracy += (correct/float(len(Y_Test)) * 100.0)\n",
    "    return accuracy/10\n",
    "\n",
    "acc = runClassifier(d)\n",
    "print(\"Average accuracy over 10 test-train splits and without ignoring missing values is %f\" % (acc))\n",
    "\n",
    "acc = runClassifier(d, True)\n",
    "print(\"Average accuracy over 10 test-train splits and ignoring missing values is %f\" % (acc))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
